{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# official code (reshape to 28x28)\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 28, 28)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    import copy\n",
    "\n",
    "    X_train, y_train = load_mnist('./data/Fashion', kind='train')\n",
    "    X_test, y_test = load_mnist('./data/Fashion', kind='t10k')\n",
    "    \n",
    "    X_train = copy.deepcopy(X_train)\n",
    "    y_train = copy.deepcopy(y_train)\n",
    "    X_test = copy.deepcopy(X_test)\n",
    "    y_test = copy.deepcopy(y_test)\n",
    "    \n",
    "    def expand_x_dims(x):\n",
    "        new_x = []\n",
    "        for i in range(len(x)):\n",
    "            x0 = x[i] / 255\n",
    "            x0 = np.expand_dims(x0, axis=0)\n",
    "            new_x.append(x0)\n",
    "        \n",
    "        return np.array(new_x)\n",
    "    \n",
    "    X_train = expand_x_dims(X_train)\n",
    "    X_test = expand_x_dims(X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(X_train, y_train, X_test, y_test):\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    \n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "    \n",
    "    train_set = TensorDataset(X_train, y_train)\n",
    "    test_set = TensorDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = make_loader(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=12*5*5, out_features=100)\n",
    "        self.fc2 = nn.Linear(in_features=100, out_features=50)\n",
    "        self.out = nn.Linear(in_features=50, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # 1st convolutional layer\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # 2nd convolutional layer\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # reshaping\n",
    "        t = t.reshape(-1, 12*5*5)\n",
    "        \n",
    "        # 1st fully-connected layer\n",
    "        t = F.relu(self.fc1(t))\n",
    "        \n",
    "        # 2nd fully-connected layer\n",
    "        t = F.relu(self.fc2(t))\n",
    "        \n",
    "        # output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "# 加载已有模型 method 1\n",
    "network1 = CNN()\n",
    "network1.load_state_dict(torch.load('./data/CNN-statedict.pth'))\n",
    "network1.eval()\n",
    "\n",
    "# 加载已有模型 method 2\n",
    "network2 = torch.load('./data/CNN-model.pth')\n",
    "network2.eval()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自主训练模型\n",
    "network = CNN()\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "epoch_num = 50\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for batch in train_loader:    # Get the batch\n",
    "        images, labels = batch\n",
    "        \n",
    "        preds = network(images)   # Pass the batch\n",
    "        loss = F.cross_entropy(preds, labels)    # Calculate the loss\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()    # Calculate the gradients\n",
    "        optimizer.step()   # Update the weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "        \n",
    "    print(\"Epoch:{} , accuracy:{:.2f}% , loss:{}\".format(epoch, total_correct/len(train_set)*100, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标记 |    0    |    1    |    2     |   3   |  4   |   5    |   6   |    7    |  8  |     9    \n",
    ":--:| :-----: |:-------:|:--------:|:-----:|:----:|:------:|:-----:|:-------:|:---:|:---------:\n",
    "类别 | T-shirt | Trouser | Pullover | Dress | Coat | Sandal | Shirt | Sneaker | Bag | Ankle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化卷积层特征\n",
    "sample_batch = next(iter(train_loader))\n",
    "images, labels = sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_visualize(net, layer_num, net_input):\n",
    "    def get_one_layer(net, layer_num, net_input):\n",
    "        # 1st convolutional layer\n",
    "        t = F.relu(net.conv1(net_input))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        if layer_num == 1:\n",
    "            return t\n",
    "        \n",
    "        # 2nd convolutional layer\n",
    "        t = F.relu(net.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        if layer_num == 2:\n",
    "            return t\n",
    "        \n",
    "        # reshaping\n",
    "        t = t.reshape(-1, 12*5*5)\n",
    "        \n",
    "        # 1st fully-connected layer\n",
    "        t = F.relu(net.fc1(t))\n",
    "        if layer_num == 3:\n",
    "            return t\n",
    "        \n",
    "        # 2nd fully-connected layer\n",
    "        t = F.relu(net.fc2(t))\n",
    "        if layer_num == 4:\n",
    "            return t\n",
    "        \n",
    "        # output layer\n",
    "        t = net.out(t)\n",
    "        return t\n",
    "    \n",
    "    # visualization using matplotlib\n",
    "    x = get_one_layer(net, layer_num, net_input)\n",
    "    x = x.squeeze().detach().numpy()\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=6, figsize = (12, 2), sharex='col', sharey='row')\n",
    "    for i in range(6):\n",
    "        ax[i].imshow(x[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_visualize(network, layer_num=1, net_input=images[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_visualize(network, layer_num=2, net_input=images[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, '->', param.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
